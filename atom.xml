<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Polyglot Playground]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="http://bkarr.github.io/"/>
  <updated>2015-04-17T04:28:01.495Z</updated>
  <id>http://bkarr.github.io/</id>
  
  <author>
    <name><![CDATA[Bryan Karr]]></name>
    <email><![CDATA[bryan@polyglotplayground.com]]></email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[Shared Memory Interprocess Queue]]></title>
    <link href="http://bkarr.github.io/2015/04/16/Shared-Memory-Interprocess-Queue/"/>
    <id>http://bkarr.github.io/2015/04/16/Shared-Memory-Interprocess-Queue/</id>
    <published>2015-04-17T03:46:03.000Z</published>
    <updated>2015-04-17T04:28:01.495Z</updated>
    <content type="html"><![CDATA[<p>In attempting to build my own implementation of an interprocess queue, I was faced with two basic design issues related to the requirements I placed on myself.  The first requirement was to be able to dynamically grow the queue based on demand for memory, and the second requirement was to allow arbitrary sized messages.  I wanted no preallocation or explicit limitations.  So the design had to allow the shared memory to grow, and for all processes to be able to detect the increase and adjust as needed concurrently.  Secondly, I needed to track arbitrary allocations and deallocations within the shared memory object.  </p>
<p>Initially, a single page of 4096 bytes is allocated in shared memory, which for Linux resides in /dev/shm on the file system.  The initial allocation looks like the diagram below:</p>
<img src="/images/shrq_layout.jpg">
<p>For all processes to be able to use the queue when accessing at different virtual addresses, the memory is treated as an array of signed 64-bit integers so that the embedded data structures are all updated based on calculated offsets instead of pointers.  There is a 512-byte header that contains the base of all the basic embedded data structures.  Those data structures include three separate semaphores, lock-free lists for the queues, and a critbit tree for tracking freed data allocations.  Both the critbit tree and the lists use the same size internal nodes, which have to be double-word aligned.  All node allocations are performed from the left to guarantee alignment, whereas, the data allocations can be an arbitrary number of array slots proceed from the right when looking at the diagram.  The array is always grown in multiples of 4096-byte page size and the allocation schemes for each type is maintained by advancing the allocation counters to the left and right of the newly allocated pages.</p>
<p>Unfortunately, I could not figure out a way to manage a lock-free concurrent expansion across multiple processes so I had to use a dedicated semaphore in the header as a mutex such that only one process at a time can expand the shared memory.  That way any accessing process is able to safely expand using ftruncate() through the use of a shared semaphore.  Every access of the shared memory by other processes is guarded by a range check on the index to make sure it is in bounds, otherwise, the enlarged shared memory is remapped before proceeding.  In this manner, I am able to have any given process expand the shared memory queue and have all other processes detect and adjust.</p>
<p>As previously mentioned, I use a critbit tree to track freed data allocations based on the implementation described in this <a href="https://www.imperialviolet.org/binary/critbit.pdf" target="_blank" rel="external">paper</a>.  I chose that particular data structure because it minimizes the number of internal nodes which minimizes the memory references.  I believe that in typical usage that messages on the queue will grouped within a typical range so that the tree in most cases will remain quite small.  The key used is the number of 64-bit integer slots in the array the memory allocation occupies, which means that endianness of the native CPU architecture affects the implementation.  Since I have access to only Intel CPUs, the code is written for little-endian integer keys.</p>
<p>The actual queue is built based on the lock-free queue implementation described by Maged Michael and Michael Scott in this <a href="http://www.research.ibm.com/people/m/michael/podc-1996.pdf" target="_blank" rel="external">paper</a>.  It is probably the best known and most widely used lock-free queue algorithm.  Doug Lea used it as the basis for concurrent queues in java.util.concurrent libraries for Java.  The book <u>The Art of Multiprocessor Programming</u> by Maurice Herlihy and Nir Shavit also describes the algorithms involved and the issues surrounding them in detail.  There are two explicit queues embedded with one for messages and the other for events.  Also, when internal nodes are freed, they are essentially queued on a free list.</p>
<p>The conceptual diagram below illustrates a queue with a couple of items enqueued:</p>
<img src="/images/shrq_enqueued.jpg">
<p>In the diagram, I use the arrows as if they are pointers, where in the actual implementation they are actually integer index references rather than pointer addresses on heap as would be done in a typical single process implementation.  The data for each item on queue is shown allocated to the right hand side, and queue nodes are allocated on the left.  Only node allocations end up on the actual queue.  Each node has a reference to the data location and the next node on queue.  Lastly, there is both a head reference and a tail reference maintained in the header portion of the shared memory segment.</p>
<p>Finally, there are two more semaphores that are used to track the size of the queue and allow the calling processes to block either because the queue is empty or that the queue is full.  The write semaphore is initialized to the maximum size and will allow writers to add items to queue only if it is not zero.  Every add to the queue decrements the count and every remove increments the count.  The read semaphore works just the opposite in that it is initialized to zero and reads from queue will block until something has been added.  Every add increments the semaphore count and every remove decrements the count.  By using two semaphores in such a manner, I am able to create a bounded queue that allows calling processes to block or not block as needed on both the adds and removes.  An unbounded queue is approximated by setting the write semaphore to the maximum value for a semaphore, which on a 64-bit Linux system allows 2147483648 items to be added to a queue.  </p>
]]></content>
    <summary type="html">
    <![CDATA[<p>In attempting to build my own implementation of an interprocess queue, I was faced with two basic design issues related to the requiremen]]>
    </summary>
    
      <category term="critbit tree" scheme="http://bkarr.github.io/tags/critbit-tree/"/>
    
      <category term="lock-free queue" scheme="http://bkarr.github.io/tags/lock-free-queue/"/>
    
      <category term="semaphore" scheme="http://bkarr.github.io/tags/semaphore/"/>
    
      <category term="Design" scheme="http://bkarr.github.io/categories/Design/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Development Plans]]></title>
    <link href="http://bkarr.github.io/2015/04/14/Development-Plans/"/>
    <id>http://bkarr.github.io/2015/04/14/Development-Plans/</id>
    <published>2015-04-14T23:08:59.000Z</published>
    <updated>2015-04-14T23:08:59.124Z</updated>
    <content type="html"><![CDATA[<p>As I said in my previous post, I would like to explore alternative means of communicating between programs written in different languages, and then using those components to assemble working applications.  </p>
<p>I see three major steps to this effort:</p>
<ul>
<li>develop data structures in shared memory to simplify interprocess communication in C</li>
<li>use foreign function interfaces in various languages to use those data structures</li>
<li>develop scripting to assemble programs written in various languages to assemble working applications</li>
</ul>
<p>Because there are several shared memory data structures I have in mind, I do not intend to complete each step before proceeding to the next. Rather, I intend to iteratively go through these steps for each data structure.  For example, the first data structure I am building is a new, improved version of the interprocess queue that is simpler to use and much more functional than OS based implementations currently available.  It would be quite useful to at least partially complete steps two and three before moving on to the next data structure.  In fact, the majority of the benefit will come from completing those steps for the shared memory queue.</p>
<p>The three data structures I have in mind at this point, all to go in the same library, are as follows:</p>
<ul>
<li>shared memory queue that can grow dynamically and has no limits on message sizes</li>
<li>shared memory allocator that allows dynamically allocating portions of memory that can be referenced through a passed token</li>
<li>shared memory map for storing and accessing key/value pairs using arbitrary data as keys and values</li>
</ul>
<p>I am beginning with the shared memory queue because that allows me to pass messages between programs and simulate both Actor and communicating sequential processes (CSP) models of computation.  The shared memory allocator is an idea that occurred to me while considering how I would practically build applications using the queue.  The queue is designed to handle messages of arbitrary length, but the occasional large message would cause all queues it was placed on to grow to an unnecessary size for just that one message.  My solution is allocate space in shared memory associated with a token that can be passed via the queue and to allow the safe access of that memory through the use of the token.  Lastly, the associative shared memory map is on the agenda as a generally useful data structure for building multiple types of applications.  The Lua language, for example, demonstrates the utility of the associative array, or table in its vernacular, for implementing multiple software development paradigms.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>As I said in my previous post, I would like to explore alternative means of communicating between programs written in different languages]]>
    </summary>
    
      <category term="Plans" scheme="http://bkarr.github.io/categories/Plans/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Why this blog?]]></title>
    <link href="http://bkarr.github.io/2015/04/13/Why-this-blog/"/>
    <id>http://bkarr.github.io/2015/04/13/Why-this-blog/</id>
    <published>2015-04-13T19:34:02.000Z</published>
    <updated>2015-04-14T04:52:28.285Z</updated>
    <content type="html"><![CDATA[<p>I was first inspired to start this blog after reading several blog posts about steps to take regarding career development.  The posts suggested multiple ways to begin such as learning a new programming language, starting an open source project on github, or begin writing a blog.  Since I really have not done anything regarding career development for several years, I have decided to do all three at once.  </p>
<p>My first problem with regard to this blog is “what to write about?”  I am not particularly fond of writing as a form of recreation.  Neither do I want to add to the plethora of abandoned blogs of programmers proffering their hard won experience, only to quickly run out of things to say.  So, I need a project to write about since I have no desire to write a software development advice column.</p>
<p>I also want to explore ideas that had cropped up in my day-to-day work activities as a systems developer, only to be told that “this is not an R&amp;D project.”  Understandably, the company I work for doesn’t have the time and money for me to follow all my ideas to a logical conclusion, especially if they do not work out successfully.  Besides, there are obviously already off-the-shelf software products that will do most of what is needed already to build software using traditional software development techniques, and there are folks that are not fond of my adding my own contributions to the ever increasing pile of infrastructure software we are currently maintaining.  So, I have unfulfilled ambitions regarding alternatives for how software should interact and be built.</p>
<p>This blog, and its associated projects, are about a specific problem I am choosing to explore.  I want to address how programs that are written in different languages communicate, and, in simplifying those mechanisms, consider how applications might be built differently by assembling them out of communicating parts.  I realize there are lots of approaches to these issues already. I am not promising ground breaking research here; just a running dialogue while I “scratch an itch”, so to speak.  Hopefully, in addition to the blog, you will see working code in my github repositories that will be useful in some context.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>I was first inspired to start this blog after reading several blog posts about steps to take regarding career development.  The posts sug]]>
    </summary>
    
      <category term="blogging" scheme="http://bkarr.github.io/tags/blogging/"/>
    
      <category term="Personal" scheme="http://bkarr.github.io/categories/Personal/"/>
    
  </entry>
  
</feed>